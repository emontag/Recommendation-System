{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loads train and test data\n",
    "Makes repspective ratings matrix\n",
    "Can run code (with proper uncommenting) for both bias and bias removed model\n",
    "Does training and validation on the model\n",
    "Gives top 5 recommendations from test users in the model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import rand as sprand\n",
    "from scipy.sparse import lil_matrix\n",
    "import scipy\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in data\n",
    "#change name to dataset as want to load different one. For example r5train to r4train\n",
    "#do this for the different experiments\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df_train = pd.read_csv('ml-10M100K/r5.train', sep='::', names=names,engine='python')\n",
    "df_test = pd.read_csv('ml-10M100K/r5.test', sep='::', names=names,engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838985046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>231</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>292</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        1      122     5.0  838985046\n",
       "1        1      185     5.0  838983525\n",
       "2        1      231     5.0  838983392\n",
       "3        1      292     5.0  838983421\n",
       "4        1      316     5.0  838983392"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal get the matrix of the users to the items ratings\n",
    "def get_movielens_ratings(df):\n",
    "    n_users = max(df.user_id.unique())\n",
    "    n_items = max(df.item_id.unique())\n",
    "\n",
    "    interactions = lil_matrix( (n_users,n_items), dtype=float) #np.zeros((n_users, n_items))\n",
    "    for row in df.itertuples():\n",
    "        interactions[row[1] - 1, row[2] - 1] = row[3]\n",
    "    return interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used for dataset r5 due to discrepancy in size between r5train and r5 test users\n",
    "def get_movielens_ratings_other(df):\n",
    "    n_users = max(df.user_id.unique())\n",
    "    n_items = max(df.item_id.unique())\n",
    "\n",
    "    interactions = lil_matrix( (71567,65133), dtype=float) #np.zeros((n_users, n_items))\n",
    "    for row in df.itertuples():\n",
    "        interactions[row[1] - 1, row[2] - 1] = row[3]\n",
    "    return interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71567, 65133)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = get_movielens_ratings_other(df_train)\n",
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71567, 65133)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratings = get_movielens_ratings(df_test)\n",
    "test_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to make the model\n",
    "#for use with bias in forward use the firsr return statement in method uncomment it) \n",
    "#for removal of bias use the \"pred=\" code and below and return pred\n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_users, n_items, n_factors=5):\n",
    "        super().__init__()\n",
    "        self.user_factors = torch.nn.Embedding(n_users, \n",
    "                                               n_factors,\n",
    "                                               sparse=False)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, \n",
    "                                               n_factors,\n",
    "                                               sparse=False)\n",
    "        self.user_biases = torch.nn.Embedding(n_users, \n",
    "                                              1,\n",
    "                                              sparse=False)\n",
    "        self.item_biases = torch.nn.Embedding(n_items,\n",
    "                                              1,\n",
    "                                              sparse=False)\n",
    "        # Also should consider fitting overall bias (self.mu term) and both user and item bias vectors\n",
    "        # Mu is 1x1, user_bias is 1xn_users. item_bias is 1xn_items\n",
    "    \n",
    "    # For convenience when we want to predict a sinble user-item pair. \n",
    "    def predict(self, user, item):\n",
    "        # Need to fit bias factors\n",
    "        #return (pred + self.user_factors(user) * self.item_factors(item)).sum(1)\n",
    "        pred = self.user_biases(user) + self.item_biases(item)\n",
    "        pred += (self.user_factors(user) * self.item_factors(item)).sum(1)\n",
    "        return pred\n",
    "    \n",
    "    # Much more efficient batch operator. This should be used for training purposes\n",
    "    def forward(self, users, items):\n",
    "      #use line below for bias incorporated\n",
    "      #  return torch.mm(self.user_factors(users),torch.transpose(self.item_factors(items),0,1))\n",
    "        #use below for bias removal\n",
    "        pred = torch.mm(self.user_factors(users),torch.transpose(self.item_factors(items),0,1))\n",
    "        #print (users)\n",
    "        #print (items)\n",
    "        i=torch.transpose(self.item_biases(items),0,1)\n",
    "        pred += i.expand_as(pred)\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MatrixFactorization(ratings.shape[0], ratings.shape[1], n_factors=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change weight_decay for regulirization of the model while training\n",
    "reg_loss_func = torch.optim.Adam(model.parameters(), lr=1e-6, weight_decay=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size,ratings):\n",
    "    # Sort our data and scramble it\n",
    "    rows, cols = ratings.shape\n",
    "    p = np.random.permutation(rows)\n",
    "    \n",
    "    # create batches\n",
    "    sindex = 0\n",
    "    eindex = batch_size\n",
    "    while eindex < rows:\n",
    "        batch = p[sindex:eindex]\n",
    "        temp = eindex\n",
    "        eindex = eindex + batch_size\n",
    "        sindex = temp\n",
    "        yield batch\n",
    "    \n",
    "    if eindex >= rows:\n",
    "        batch = range(sindex,rows)\n",
    "        yield batch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 2\n",
    "BATCH_SIZE = 1000 #50\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runs validation in batches to handle some memory issues\n",
    "#appends the MSE to list of batch and takes the average of that for the overal MSE on test set \n",
    "def run_validation():\n",
    "    l = []\n",
    "    for i,batch in enumerate(get_batch(BATCH_SIZE, test_ratings)):\n",
    "            # Turn data into variables\n",
    "            interactions= Variable(torch.FloatTensor(test_ratings[batch, :].toarray()))\n",
    "            rows = Variable(torch.LongTensor(batch))\n",
    "            cols = Variable(torch.LongTensor(np.arange(ratings.shape[1])))\n",
    "            try:\n",
    "                predictions = model(rows, cols)\n",
    "            except:\n",
    "                break\n",
    "            l.append ( loss_func(predictions, interactions).data[0])\n",
    "            \n",
    "    l = sum(l)/len(l)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trains model and calls validation on each epoch\n",
    "def run_epoch():\n",
    "    for i,batch in enumerate(get_batch(BATCH_SIZE, ratings)):\n",
    "        # Set gradients to zero\n",
    "        reg_loss_func.zero_grad()\n",
    "        \n",
    "        # Turn data into variables\n",
    "        interactions = Variable(torch.FloatTensor(ratings[batch, :].toarray()))\n",
    "        rows = Variable(torch.LongTensor(batch))\n",
    "        cols = Variable(torch.LongTensor(np.arange(ratings.shape[1])))\n",
    "    \n",
    "        # Predict and calculate loss\n",
    "        predictions = model(rows, cols)\n",
    "        loss = loss_func(predictions, interactions)\n",
    "        #print (predictions.shape)\n",
    "        #print (interactions.shape)\n",
    "    \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "    \n",
    "        # Update the parameters\n",
    "        reg_loss_func.step()\n",
    "    print(\"train loss is \"+str(loss))\n",
    "   \n",
    "    \n",
    "    #interactions = Variable(torch.FloatTensor(test_ratings[,:].toarray()))\n",
    "    #rows = Variable(torch.LongTensor(users.toarray()))\n",
    "    #cols = Variable(torch.LongTensor(np.arange(ratings.shape[1])))\n",
    "    loss=run_validation()\n",
    "    # Predict and calculate loss\n",
    "    #predictions = model(rows, cols)\n",
    "    #loss = loss_func(predictions, interactions)\n",
    "    print(\"test loss is \"+str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "train loss is Variable containing:\n",
      " 2.8232\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "test loss is 2.4715017312102847\n",
      "1\n",
      "train loss is Variable containing:\n",
      " 2.8227\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "test loss is 2.47257090277142\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCH):\n",
    "    print(i)\n",
    "    run_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 3\n",
    "#gets predictions on model on test set by batch\n",
    "#gets predictions by user and takes the max 5 of those predictions into a list\n",
    "#writes user id and list of recommendations to file \n",
    "def recommend():\n",
    "    num=0\n",
    "    with open('assign5_r5results.tsv', 'w') as file:\n",
    "        for i,batch in enumerate(get_batch(BATCH_SIZE, test_ratings)):\n",
    "                # Turn data into variables\n",
    "                #interactions= Variable(torch.FloatTensor(test_ratings[batch, :].toarray()))\n",
    "                rows = Variable(torch.LongTensor(batch))\n",
    "                cols = Variable(torch.LongTensor(np.arange(ratings.shape[1])))\n",
    "                predictions = model(rows, cols)\n",
    "                for j,line in enumerate(predictions):\n",
    "                    a=predictions[j].data.numpy()\n",
    "                    ind = np.argpartition(a, -5)[-5:]\n",
    "                    file.write(str(num))\n",
    "                    for k in ind:\n",
    "                        file.write(\"\\t\"+str(k))\n",
    "                    num+=1\n",
    "                    file.write(\"\\n\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calls recommendations function to write to file\n",
    "recommend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
